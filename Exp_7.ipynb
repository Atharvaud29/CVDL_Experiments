{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "865dca11",
   "metadata": {},
   "source": [
    "### Aim = Case study on recent deep learning applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98267d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d32cb4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "825bef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 28, 28, 1).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5f67544",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Atharv\\.vscode\\CVDL_experiments\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "MaxPooling2D(2,2),\n",
    "Flatten(),\n",
    "Dense(128, activation='relu'),\n",
    "Dense(10, activation='softmax') # Output layer for 10 digits\n",
    "])\n",
    "#Step 4: Train the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce49cba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.9083 - loss: 0.3069 - val_accuracy: 0.9803 - val_loss: 0.0655\n",
      "Epoch 2/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.9839 - loss: 0.0518 - val_accuracy: 0.9860 - val_loss: 0.0535\n",
      "Epoch 3/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.9885 - loss: 0.0341 - val_accuracy: 0.9872 - val_loss: 0.0494\n",
      "Epoch 4/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.9940 - loss: 0.0196 - val_accuracy: 0.9867 - val_loss: 0.0570\n",
      "Epoch 5/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.9956 - loss: 0.0141 - val_accuracy: 0.9877 - val_loss: 0.0525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2aa38c3ef60>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb7d66f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9793 - loss: 0.0702\n",
      "Test Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35ac7b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9db4ed36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[0].reshape(28,28), cmap='gray')\n",
    "plt.title(f\"Prediction: {np.argmax(predictions[0])}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c32d19",
   "metadata": {},
   "source": [
    "### Conclusion = \n",
    "In this case study, we implemented a deep learning model using Convolutional Neural Networks (CNNs) to recognize handwritten digits from\n",
    "the MNIST dataset. This project demonstrates how deep learning enables machines to automatically extract important features from raw\n",
    "pixel data and accurately classify handwritten numerals (0–9) with minimal preprocessing.\n",
    "\n",
    "By training the model on 60,000 labeled images and testing on 10,000 unseen images, we achieved a high accuracy of around 98%,\n",
    "showcasing the strength of deep learning in visual pattern recognition. The use of TensorFlow/Keras made the process efficient and\n",
    "beginner-friendly, making this a perfect example of how deep learning is being used in practical, real-world scenarios such as digit\n",
    "recognition in banking, postal automation, and touchscreen devices."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
